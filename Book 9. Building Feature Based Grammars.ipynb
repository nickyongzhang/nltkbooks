{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammatical Features\n",
    " In this chapter, we will investigate the role of features in building rule-based grammars. In contrast to feature extractors, which record features that have been automatically detected, we are now going to declare the features of words and phrases. We start off with a very simple example, using dictionaries to store features and their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "kim = {'CAT': 'NP','ORTH':'Kim','REF':'k'}\n",
    "chase = {'CAT': 'V','ORTH':'chased','REL':'chase'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objects kim and chase both have a couple of shared features, CAT (grammatical category) and ORTH (orthography, i.e., spelling). In addition, each has a more semantically-oriented feature: kim['REF'] is intended to give the referent of kim, while chase['REL'] gives the relation expressed by chase. In the context of rule-based grammars, such pairings of features and values are known as **feature structures**.\n",
    "\n",
    "Feature structures contain various kinds of information about grammatical entities. The information need not be exhaustive, and we might want to add further properties. For example, in the case of a verb, it is often useful to know what \"semantic role\" is played by the arguments of the verb. In the case of chase, the subject plays the role of \"agent\", while the object has the role of \"patient\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chase['AGT'] = 'sbj'\n",
    "chase['PAT'] = 'obj'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORTH  => chased\n",
      "REL   => chase\n",
      "AGT   => k\n",
      "PAT   => l\n"
     ]
    }
   ],
   "source": [
    "sent = 'Kim chased Lee'\n",
    "tokens = sent.split()\n",
    "lee = {'CAT':'NP','ORTH':'Lee','REF':'l'}\n",
    "def lex2fs(word):\n",
    "    for fs in [kim,lee,chase]:\n",
    "        if fs['ORTH'] == word:\n",
    "            return fs\n",
    "        \n",
    "subj, verb, obj = lex2fs(tokens[0]),lex2fs(tokens[1]),lex2fs(tokens[2])\n",
    "verb['AGT'] = subj['REF']\n",
    "verb['PAT'] = obj['REF']\n",
    "for k in ['ORTH','REL','AGT','PAT']:\n",
    "    print('%-5s => %s' % (k,verb[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same approach could be adopted for a different verb, say surprise, though in this case, the subject would play the role of \"source\" (SRC) and the object, the role of \"experiencer\" (EXP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise = {'CAT':'V','ORTH':'surprised','REL':'surprise',\n",
    "           'SRC':'sbj','EXP':'obj'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntactic Agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That morphological properties of the verb co-vary with syntactic properties of the subject noun phrase. This co-variance is called **agreement**. If we look further at verb agreement in English, we will see that present tense verbs typically have two inflected forms: one for third person singular, and another for every other combination of person and number, as shown in Table below.\n",
    "\n",
    "*Agreement Paradigm for English Regular Verbs*\n",
    "\n",
    "| |singular|plural|\n",
    "|-|------|------|\n",
    "|1st per|I run|we run|\n",
    "|2nd per|you run|you run|\n",
    "|3rd per|he/she/it runs|they run|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "S   ->   NP VP\n",
    "NP  ->   Det N\n",
    "VP  ->   V\n",
    "\n",
    "Det  ->  'this'\n",
    "N    ->  'dog'\n",
    "V    ->  'runs'\n",
    "```\n",
    "\n",
    "To\n",
    "```\n",
    "S -> NP_SG VP_SG\n",
    "S -> NP_PL VP_PL\n",
    "NP_SG -> Det_SG N_SG\n",
    "NP_PL -> Det_PL N_PL\n",
    "VP_SG -> V_SG\n",
    "VP_PL -> V_PL\n",
    "\n",
    "Det_SG -> 'this'\n",
    "Det_PL -> 'these'\n",
    "N_SG -> 'dog'\n",
    "N_PL -> 'dogs'\n",
    "V_SG -> 'runs'\n",
    "V_PL -> 'run'\n",
    "```\n",
    "The change results in the sentences generated by grammar can involve both singular subject NPS and VPS, and plural subject NPS and VPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Attributes and Constraits\n",
    "```\n",
    "S -> NP[NUM=?n] VP[NUM=?n]\n",
    "NP[NUM=?n] -> Det[NUM=?n] N[NUM=?n]\n",
    "VP[NUM=?n] -> V[NUM=?n]\n",
    "```\n",
    "\n",
    "We have introduced some new notation which says that the category N has a (grammatical) **feature** called NUM (short for 'number'), We are using ?n as a variable over values of NUM; it can be instantiated either to sg or pl, within a given production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% start S\n",
      "# ###################\n",
      "# Grammar Productions\n",
      "# ###################\n",
      "# S expansion productions\n",
      "S -> NP[NUM=?n] VP[NUM=?n]\n",
      "# NP expansion productions\n",
      "NP[NUM=?n] -> N[NUM=?n] \n",
      "NP[NUM=?n] -> PropN[NUM=?n] \n",
      "NP[NUM=?n] -> Det[NUM=?n] N[NUM=?n]\n",
      "NP[NUM=pl] -> N[NUM=pl] \n",
      "# VP expansion productions\n",
      "VP[TENSE=?t, NUM=?n] -> IV[TENSE=?t, NUM=?n]\n",
      "VP[TENSE=?t, NUM=?n] -> TV[TENSE=?t, NUM=?n] NP\n",
      "# ###################\n",
      "# Lexical Productions\n",
      "# ###################\n",
      "Det[NUM=sg] -> 'this' | 'every'\n",
      "Det[NUM=pl] -> 'these' | 'all'\n",
      "Det -> 'the' | 'some' | 'several'\n",
      "PropN[NUM=sg]-> 'Kim' | 'Jody'\n",
      "N[NUM=sg] -> 'dog' | 'girl' | 'car' | 'child'\n",
      "N[NUM=pl] -> 'dogs' | 'girls' | 'cars' | 'children' \n",
      "IV[TENSE=pres,  NUM=sg] -> 'disappears' | 'walks'\n",
      "TV[TENSE=pres, NUM=sg] -> 'sees' | 'likes'\n",
      "IV[TENSE=pres,  NUM=pl] -> 'disappear' | 'walk'\n",
      "TV[TENSE=pres, NUM=pl] -> 'see' | 'like'\n",
      "IV[TENSE=past] -> 'disappeared' | 'walked'\n",
      "TV[TENSE=past] -> 'saw' | 'liked'\n"
     ]
    }
   ],
   "source": [
    "nltk.data.show_cfg('grammars/book_grammars/feat0.fcfg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that a syntactic category can have more than one feature; for example, V[TENSE=pres, NUM=pl]. In general, we can add as many features as we like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|.Kim .like.chil.|\n",
      "Leaf Init Rule:\n",
      "|[----]    .    .| [0:1] 'Kim'\n",
      "|.    [----]    .| [1:2] 'likes'\n",
      "|.    .    [----]| [2:3] 'children'\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[----]    .    .| [0:1] PropN[NUM='sg'] -> 'Kim' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[----]    .    .| [0:1] NP[NUM='sg'] -> PropN[NUM='sg'] *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|[---->    .    .| [0:1] S[] -> NP[NUM=?n] * VP[NUM=?n] {?n: 'sg'}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    [----]    .| [1:2] TV[NUM='sg', TENSE='pres'] -> 'likes' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    [---->    .| [1:2] VP[NUM=?n, TENSE=?t] -> TV[NUM=?n, TENSE=?t] * NP[] {?n: 'sg', ?t: 'pres'}\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [----]| [2:3] N[NUM='pl'] -> 'children' *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [----]| [2:3] NP[NUM='pl'] -> N[NUM='pl'] *\n",
      "Feature Bottom Up Predict Combine Rule:\n",
      "|.    .    [---->| [2:3] S[] -> NP[NUM=?n] * VP[NUM=?n] {?n: 'pl'}\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|.    [---------]| [1:3] VP[NUM='sg', TENSE='pres'] -> TV[NUM='sg', TENSE='pres'] NP[] *\n",
      "Feature Single Edge Fundamental Rule:\n",
      "|[==============]| [0:3] S[] -> NP[NUM='sg'] VP[NUM='sg'] *\n",
      "(S[]\n",
      "  (NP[NUM='sg'] (PropN[NUM='sg'] Kim))\n",
      "  (VP[NUM='sg', TENSE='pres']\n",
      "    (TV[NUM='sg', TENSE='pres'] likes)\n",
      "    (NP[NUM='pl'] (N[NUM='pl'] children))))\n"
     ]
    }
   ],
   "source": [
    "tokens = 'Kim likes children'.split()\n",
    "from nltk import load_parser\n",
    "cp = load_parser('grammars/book_grammars/feat0.fcfg',trace=2)\n",
    "for tree in cp.parse(tokens):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminology\n",
    "So far, we have only seen feature values like sg and pl. These simple values are usually called **atomic** â€” that is, they can't be decomposed into subparts. A special case of atomic values are **boolean** values, that is, values that just specify whether a property is true or false. For example, we might want to distinguish **auxiliary** verbs such as can, may, will and do with the boolean feature AUX. For example, the production V[TENSE=pres, AUX=+] -> 'can' means that can receives the value pres for TENSE and + or true for AUX. There is a widely adopted convention which abbreviates the representation of boolean features f; instead of AUX=+ or AUX=-, we use +AUX and -AUX respectively. These are just abbreviations, however, and the parser interprets them as though + and - are like any other atomic value. \n",
    "```\n",
    "V[TENSE=pres, +AUX] -> 'can'\n",
    "V[TENSE=pres, +AUX] -> 'may'\n",
    "\n",
    "V[TENSE=pres, -AUX] -> 'walks'\n",
    "V[TENSE=pres, -AUX] -> 'likes'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have spoken of attaching \"feature annotations\" to syntactic categories. A more radical approach represents the whole category â€” that is, the non-terminal symbol plus the annotation â€” as a bundle of features. For example, N[NUM=sg] contains part of speech information which can be represented as POS=N. An alternative notation for this category therefore is [POS=N, NUM=sg].\n",
    "\n",
    "In addition to atomic-valued features, features may take values that are themselves feature structures. For example, we can group together agreement features (e.g., person, number and gender) as a distinguished part of a category, grouped together as the value of *AGR*. In this case, we say that AGR has a **complex** value. Below depicts the structure, in a format known as an **attribute value matrix** (AVM).\n",
    "```\n",
    "[POS = N           ]\n",
    "[                  ]\n",
    "[AGR = [PER = 3   ]]\n",
    "[      [NUM = pl  ]]\n",
    "[      [GND = fem ]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the possibility of using features like AGR, we can refactor a grammar like 1.1 so that agreement features are bundled together. A tiny grammar illustrating this idea is shown in \n",
    "```\n",
    "S                    -> NP[AGR=?n] VP[AGR=?n]\n",
    "NP[AGR=?n]           -> PropN[AGR=?n]\n",
    "VP[TENSE=?t, AGR=?n] -> Cop[TENSE=?t, AGR=?n] Adj\n",
    "\n",
    "Cop[TENSE=pres,  AGR=[NUM=sg, PER=3]] -> 'is'\n",
    "PropN[AGR=[NUM=sg, PER=3]]            -> 'Kim'\n",
    "Adj                                   -> 'happy'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Feature Structures\n",
    "Feature structures in NLTK are declared with the FeatStruct() constructor. Atomic feature values can be strings or integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ NUM   = 'sg'   ]\n",
      "[ TENSE = 'past' ]\n"
     ]
    }
   ],
   "source": [
    "fs1 = nltk.FeatStruct(TENSE='past',NUM='sg')\n",
    "print(fs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A feature structure is actually just a kind of dictionary, and so we access its values by indexing in the usual way. We can use our familiar syntax to assign values to features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fem\n"
     ]
    }
   ],
   "source": [
    "fs1 = nltk.FeatStruct(PER=3,NUM='pl',GND='fem')\n",
    "print(fs1['GND'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CASE='acc', GND='fem', NUM='pl', PER=3]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs1['CASE']='acc'\n",
    "fs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
