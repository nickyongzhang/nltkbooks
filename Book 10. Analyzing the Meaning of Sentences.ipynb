{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Understanding\n",
    "## Querying a Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Problem*\n",
    "\n",
    "a.\t\tWhich country is Athens in?\n",
    "\n",
    "b.\t\tGreece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 1.1:\n",
    "\n",
    "city_table: A table of cities, countries and populations\n",
    "\n",
    "|City|Country|Population|\n",
    "|----|-------|----------|\n",
    "|athens|greece|1368|\n",
    "|bangkok|thailand|1178|\n",
    "|barcelona|spain|1280|\n",
    "|berlin|east_germany|3481|\n",
    "|birmingham|united_kingdom|1112|\n",
    "\n",
    "SQL `\tSELECT Country FROM city_table WHERE City = 'athens'` can easily get the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to translate English input to SQL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% start S\n",
      "S[SEM=(?np + WHERE + ?vp)] -> NP[SEM=?np] VP[SEM=?vp]\n",
      "VP[SEM=(?v + ?pp)] -> IV[SEM=?v] PP[SEM=?pp]\n",
      "VP[SEM=(?v + ?ap)] -> IV[SEM=?v] AP[SEM=?ap]\n",
      "NP[SEM=(?det + ?n)] -> Det[SEM=?det] N[SEM=?n]\n",
      "PP[SEM=(?p + ?np)] -> P[SEM=?p] NP[SEM=?np]\n",
      "AP[SEM=?pp] -> A[SEM=?a] PP[SEM=?pp]\n",
      "NP[SEM='Country=\"greece\"'] -> 'Greece'\n",
      "NP[SEM='Country=\"china\"'] -> 'China'\n",
      "Det[SEM='SELECT'] -> 'Which' | 'What'\n",
      "N[SEM='City FROM city_table'] -> 'cities'\n",
      "IV[SEM=''] -> 'are'\n",
      "A[SEM=''] -> 'located'\n",
      "P[SEM=''] -> 'in'\n"
     ]
    }
   ],
   "source": [
    "nltk.data.show_cfg('grammars/book_grammars/sql0.fcfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT City FROM city_table WHERE Country=\"china\"\n"
     ]
    }
   ],
   "source": [
    "from nltk import load_parser\n",
    "cp = load_parser('grammars/book_grammars/sql0.fcfg')\n",
    "query = 'What cities are located in China'\n",
    "trees = list(cp.parse(query.split()))\n",
    "answer = trees[0].label()['SEM']\n",
    "answer = [s for s in answer if s]\n",
    "q = ' '.join(answer)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canton chungking dairen harbin kowloon mukden peking shanghai sian tientsin "
     ]
    }
   ],
   "source": [
    "from nltk.sem import chat80\n",
    "rows = chat80.sql_query('corpora/city_database/city.db', q)\n",
    "for r in rows: \n",
    "    print(r[0], end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language, Semantics and Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadly speaking, logic-based approaches to natural language semantics focus on those aspects of natural language which guide our judgments of consistency and inconsistency. The syntax of a logical language is designed to make these features formally explicit. As a result, determining properties like consistency can often be reduced to symbolic manipulation, that is, to a task that can be carried out by a computer. In order to pursue this approach, we first want to develop a technique for representing a possible situation. We do this in terms of something that logicians call a model.\n",
    "\n",
    "A **model** for a set W of sentences is a formal representation of a situation in which all the sentences in W are true. The usual way of representing models involves set theory. The domain D of discourse (all the entities we currently care about) is a set of individuals, while relations are treated as sets built up from D. Let's look at a concrete example. Our domain D will consist of three children, Stefan, Klaus and Evi, represented respectively as s, k and e. We write this as D = {s, k, e}. The expression boy denotes the set consisting of Stefan and Klaus, the expression girl denotes the set consisting of Evi, and the expression is running denotes the set consisting of Stefan and Evi. 1.2 is a graphical rendering of the model.\n",
    "\n",
    "Figure 1.2\n",
    "![](http://www.nltk.org/images/model_kids.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propositional Logic\n",
    "A logical language is designed to make reasoning formally explicit. As a result, it can capture aspects of natural language which determine whether a set of sentences is consistent. As part of this approach, we need to develop logical representations of a sentence φ which formally capture the **truth-conditions** of φ. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Propositional logic** allows us to represent just those parts of linguistic structure which correspond to certain sentential connectives. We have just looked at and. Other such connectives are not, or and if..., then.... In the formalization of propositional logic, the counterparts of such connectives are sometimes called **boolean operators**. The basic expressions of propositional logic are **propositional symbols**, often written as P, Q, R, etc. There are varying conventions for representing boolean operators. Since we will be focusing on ways of exploring logic within NLTK, we will stick to the following ASCII versions of the operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negation       \t-\n",
      "conjunction    \t&\n",
      "disjunction    \t|\n",
      "implication    \t->\n",
      "equivalence    \t<->\n"
     ]
    }
   ],
   "source": [
    "nltk.boolean_ops()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the propositional symbols and the boolean operators we can build an infinite set of **well formed formulas** (or just formulas, for short) of propositional logic. First, every propositional letter is a formula. Then if φ is a formula, so is -φ. And if φ and ψ are formulas, then so are (φ & ψ) (φ | ψ) (φ -> ψ) (φ <-> ψ).\n",
    "\n",
    "Table 2.1:\n",
    "\n",
    "Truth conditions for the Boolean Operators in Propositional Logic.\n",
    "\n",
    "|Boolean Operator|Truth Conditions|\n",
    "|----------------|----------------|\n",
    "|negation (it is not the case that ...)\t-φ is true in s|iff\tφ is false in s|\n",
    "|conjunction (and)\t(φ & ψ) is true in s|iff\tφ is true in s and ψ is true in s|\n",
    "|disjunction (or)\t(φ &#124; ψ) is true in s|iff\tφ is true in s or ψ is true in s|\n",
    "|implication (if ..., then ...)\t(φ -> ψ) is true in s|iff\tφ is false in s or ψ is true in s|\n",
    "|equivalence (if and only if)\t(φ <-> ψ) is true in s|iff\tφ and ψ are both true in s or both false in s|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<NegatedExpression -(P & Q)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_expr = nltk.sem.Expression.fromstring\n",
    "read_expr('-(P & Q)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AndExpression (P & Q)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_expr('P & Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OrExpression (P | (R -> Q))>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_expr('P | (R -> Q)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IffExpression (P <-> --P)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_expr('P <-> -- P')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logical proofs can be carried out with NLTK's inference module, for example via an interface to the third-party theorem prover Prover9. The inputs to the inference mechanism first have to be converted into logical expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp = nltk.sem.Expression.fromstring\n",
    "SnF = read_expr('SnF')\n",
    "NotFnS = read_expr('-FnS')\n",
    "R = read_expr('SnF -> -FnS')\n",
    "prover = nltk.Prover9()\n",
    "prover.prove(NotFnS,[SnF,R])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = nltk.Valuation([('P',True),('Q',True),('R',False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val['P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "dom = set()\n",
    "g = nltk.Assignment(dom)\n",
    "\n",
    "m = nltk.Model(dom,val)\n",
    "print(m.evaluate('(P & Q)',g))\n",
    "print(m.evaluate('-(P & Q)',g))\n",
    "print(m.evaluate('(P & R)',g))\n",
    "print(m.evaluate('(P | R)',g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First-Prder Logic\n",
    "## Syntax\n",
    "The standard construction rules for first-order logic recognize terms such as individual variables and individual constants, and predicates which take differing numbers of arguments. For example, *Angus walks* might be formalized as *walk(angus)* and *Angus sees Bertie* as *see(angus, bertie)*. We will call *walk* a **unary predicate**, and *see* a **binary predicate**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often helpful to inspect the syntactic structure of expressions of first-order logic, and the usual way of doing this is to assign types to expressions. Following the tradition of Montague grammar, we will use two **basic types**: e is the type of entities, while t is the type of formulas, i.e., expressions which have truth values. Given these two basic types, we can form **complex types** for function expressions. That is, given any types σ and τ, 〈σ, τ〉 is a complex type corresponding to functions from 'σ things' to 'τ things'. For example, 〈e, t〉 is the type of expressions from entities to truth values, namely unary predicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angus\n",
      "e\n",
      "walk\n",
      "<e,?>\n"
     ]
    }
   ],
   "source": [
    "read_expr = nltk.sem.Expression.fromstring\n",
    "expr = read_expr('walk(angus)',type_check=True)\n",
    "print(expr.argument)\n",
    "print(expr.argument.type)\n",
    "print(expr.function)\n",
    "print(expr.function.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig = {'walk':'<e,t>'}\n",
    "expr = read_expr('walk(angus)',signature=sig)\n",
    "expr.function.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
